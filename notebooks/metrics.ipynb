{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810e8dc4",
   "metadata": {},
   "source": [
    "# Run metrics.py on stored weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "005cb607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "from src.metrics import analyze_hessian_eigenvalues, analyze_hessian_stable_rank, analyze_weight_matrices\n",
    "weight_path = \"../model_weights/model_epoch_0.pt\"  # Path to a specific .pt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f79842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../model_weights/model_epoch_0.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Matrix stable rank\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43manalyze_hessian_stable_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/adaptive-muon/src/metrics.py:264\u001b[0m, in \u001b[0;36manalyze_hessian_stable_rank\u001b[0;34m(weight_path, batch_size, num_matvecs, top_k, distribution, device)\u001b[0m\n\u001b[1;32m    262\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Create Hessian linear operator using CurvLinOps\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[43mHessianLinearOperator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_subset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHessian dimension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mH\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mH\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/curvlinops/_torch_base.py:749\u001b[0m, in \u001b[0;36mCurvatureLinearOperator.__init__\u001b[0;34m(self, model_func, loss_func, params, data, progressbar, check_deterministic, num_data, block_sizes, batch_size_fn)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_in_shape(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_out_shape())\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_deterministic:\n\u001b[0;32m--> 749\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_deterministic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/curvlinops/_torch_base.py:944\u001b[0m, in \u001b[0;36mCurvatureLinearOperator._check_deterministic\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m     total_loss2 \u001b[38;5;241m=\u001b[39m tensor(\u001b[38;5;241m0.0\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    942\u001b[0m \u001b[38;5;66;03m# loop twice over the data loader, accumulate total quantities and compare\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;66;03m# batch quantities if the linear operator demands fixed data order\u001b[39;00m\n\u001b[0;32m--> 944\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ((X1, y1), pred1, loss1, grad1), ((X2, y2), pred2, loss2, grad2) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_prediction_loss_gradient(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_prediction_loss_gradient()\n\u001b[1;32m    946\u001b[0m ):\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFIXED_DATA_ORDER:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__check_deterministic_batch(\n\u001b[1;32m    949\u001b[0m             (X1, X2),\n\u001b[1;32m    950\u001b[0m             (y1, y2),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    955\u001b[0m             atol\u001b[38;5;241m=\u001b[39matol,\n\u001b[1;32m    956\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/curvlinops/_torch_base.py:887\u001b[0m, in \u001b[0;36mCurvatureLinearOperator.data_prediction_loss_gradient\u001b[0;34m(self, desc)\u001b[0m\n\u001b[1;32m    885\u001b[0m     normalization_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_normalization_factor(X, y)\n\u001b[1;32m    886\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_func(prediction, y)\u001b[38;5;241m.\u001b[39mmul_(normalization_factor)\n\u001b[0;32m--> 887\u001b[0m     grad_params \u001b[38;5;241m=\u001b[39m [g\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_params\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    888\u001b[0m     loss\u001b[38;5;241m.\u001b[39mdetach_()\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m (X, y), prediction, loss, grad_params\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/autograd/__init__.py:503\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    499\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    500\u001b[0m         grad_outputs_\n\u001b[1;32m    501\u001b[0m     )\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 503\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    514\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    516\u001b[0m     ):\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.10/site-packages/torch/autograd/graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Matrix stable rank\n",
    "analyze_hessian_stable_rank(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42efa67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
